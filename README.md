# APHELION_LAB
Data analysis of NASA exoplanet datasets using Python, SQL, and visualization

# ğŸŒŒ Exoplanet Data Explorer

A data analytics project that explores confirmed exoplanets using real datasets from NASAâ€™s Exoplanet Archive.  
The project demonstrates end-to-end data handling: API ingestion, cleaning, SQL storage, statistical analysis, and visualization.

---

## ğŸš€ Project Overview

This project fetches exoplanet data from NASAâ€™s Exoplanet Archive and analyzes relationships between planetary and stellar properties such as:

- Planet radius vs. host star temperature
- Orbital period distributions
- Identification of potentially Earth-like exoplanets

The goal is to showcase practical data engineering and analysis skills using real scientific datasets.

---

## ğŸ§  Key Features

- ğŸ“¡ Fetches real exoplanet data via NASA Exoplanet Archive API
- ğŸ§¹ Data cleaning and preprocessing using Pandas & NumPy
- ğŸ—„ï¸ SQL database backend for structured querying
- ğŸ“Š Statistical analysis and correlation studies
- ğŸ“ˆ Visualizations using Matplotlib & Seaborn
- ğŸ§ª Reproducible Jupyter notebooks

---

## ğŸ› ï¸ Tech Stack

- **Language:** Python
- **Data Handling:** Pandas, NumPy
- **Database:** SQLite / PostgreSQL
- **Visualization:** Matplotlib, Seaborn
- **APIs:** NASA Exoplanet Archive
- **Optional UI:** Streamlit

---

## ğŸ“ Project Structure

exoplanet-data-explorer/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Original API / CSV data (read-only)
â”‚   â”œâ”€â”€ processed/          # Cleaned & transformed datasets
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_fetch.ipynb
â”‚   â”œâ”€â”€ 02_data_cleaning.ipynb
â”‚   â”œâ”€â”€ 03_exploratory_analysis.ipynb
â”‚   â”œâ”€â”€ 04_statistical_analysis.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ nasa_exoplanet_api.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data_processing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ cleaner.py
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ correlations.py
â”‚   â”‚
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ db_manager.py
â”‚   â”‚
â”‚   â””â”€â”€ visualization/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ plots.py
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ schema.sql
â”‚   â””â”€â”€ example_queries.sql
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py               # (Optional) Streamlit dashboard
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md


# Load dataset
print(" Loading exoplanet data...")
df = pd.read_csv("data/raw/exoplanets.csv")

print("\n Data loaded successfully!")

# 1ï¸ Basic shape of the data
print("\n Dataset shape (rows, columns):")
print(df.shape)

# 2ï¸ Column names
print("\n Column names:")
print(list(df.columns))

# 3ï¸ Preview first rows
print("\n First 5 rows:")
print(df.head())

# 4ï¸ Data types
print("\n Data types:")
print(df.dtypes)

# 5 Missing values count
print("\n Missing values per column:")
print(df.isnull().sum())

# 6ï¸ Basic statistics for numeric columns
print("\n Basic statistics:")
print(df.describe())
